pdb:
  enabled: false

traefik-ingress:
  dnsNames:
    - dns: open-webui.rannet.duckdns.org
      services:
        - kind: Service
          name: ollama-open-webui 
          port: http

    - dns: ollama.rannet.duckdns.org
      services:
        - kind: Service
          name: ollama
          port: http

cnpg:
  image: ghcr.io/tensorchord/cloudnative-vectorchord:16-0.4.2
  instances: 2

vault-auth:
  vaultConnectionName: vault-secrets-operator/default
  authMethods:
    - name: on-prem
      # match this up with secret
      vaultAuthName: ollama-vso-connection-auth
      method: kubernetes
      mount: in-cluster
      config:
        role: ollama
        serviceAccount: open-webui-ollama
        audiences:
          - vault

# if PVCs get stuck in Progressing state:
# https://github.com/kubernetes-csi/csi-driver-smb/issues/821
open-webui:
  websocket:
    # enabled by default in chart v > 8
    # disabling ootb redis installation in favor of valkey
    redis:
      enabled: false
    url: redis://ollama-valkey:6379/0

  extraEnvVars:
    - name: OLLAMA_BASE_URLS
      value: ollama:11434
    - name: DATABASE_HOST
      value: owui-db-rw
    - name: DATABASE_NAME
      value: owui
    - name: DATABASE_TYPE
      value: postgres
    - name: DATABASE_PORT
      value: "5432"
    - name: VECTOR_DB
      value: pgvector

    - name: DATABASE_USER
      valueFrom:
        secretKeyRef:
          name: owui-db-superuser
          key: username
    - name: DATABASE_PASSWORD
      valueFrom:
        secretKeyRef:
          name: owui-db-superuser
          key: password

    # oidc things
    # DANGER - deploy with ONLY WEBUI_URL first
    # https://integrations.goauthentik.io/miscellaneous/open-webui/
    - name: WEBUI_URL
      value: https://open-webui.rannet.duckdns.org
    # rest of the configs should be applied after the above is deployed w/ a reliable ingress
    - name: OAUTH_CLIENT_ID
      valueFrom:
        secretKeyRef:
          name: env-secrets
          key: OAUTH_CLIENT_ID
    - name: OAUTH_CLIENT_SECRET
      valueFrom:
        secretKeyRef:
          name: env-secrets
          key: OAUTH_CLIENT_SECRET
    - name: OAUTH_PROVIDER_NAME
      valueFrom:
        secretKeyRef:
          name: env-secrets
          key: OAUTH_PROVIDER_NAME
    - name: OPENID_PROVIDER_URL
      valueFrom:
        secretKeyRef:
          name: env-secrets
          key: OPENID_PROVIDER_URL
    - name: OPENID_REDIRECT_URI
      valueFrom:
        secretKeyRef:
          name: env-secrets
          key: OPENID_REDIRECT_URI
    - name: OAUTH_MERGE_ACCOUNTS_BY_EMAIL
      value: "true"
    # enable the following after you confirm that login works and you still have admin
    - name: ENABLE_OAUTH_SIGNUP
      value: "true"
    - name: ENABLE_LOGIN_FORM
      value: "false"

  replicaCount: 1
  resources:
    requests:
      cpu: 2
      memory: 4Gi

  ingress:
    enabled: false

  # TODO: figure out what to do with this one; using cnpg below
  persistence:
    enabled: false
    size: 8Gi
    storageClass: smb
    # autogenerated by cluster on initial sync
    existingClaim: open-webui
    volumeName: pvc-be195e50-a8fb-489c-a27e-4c07ff140aab

  pipelines:
    resources:
      requests:
        cpu: 1
        memory: 4Gi
    strategy:
      type: Recreate
    persistence:
      enabled: true
      size: 2Gi
      storageClass: longhorn

  # values ref: https://github.com/otwld/ollama-helm/blob/main/values.yaml
  # https://github.com/open-webui/helm-charts/issues/17#issuecomment-2105195244
  ollama:
    enabled: true

    image:
      tag: latest
      pullPolicy: Always

    extraEnv:
      - name: OLLAMA_KEEP_ALIVE
        value: "-1"

    resources:
      requests:
        memory: "15Gi"
      limits:
        memory: "30Gi"

    ingress:
      enabled: false
    runtimeClassName: nvidia
    ollama:
      # these for some reason stall the container; processes will literally hang
      # not sure if this is because Im running these off of a NAS
      # models:
      #   pull:
      #     - gemma3:12B
      #     - gemma3:27B
      #     - qwen2.5-coder:14b-base-q6_K
      #     - qwen2.5-coder:32b-base-q6_K
      #   run:
      #     - gemma3:4B
      #     # - gemma3:27B
      #     # - qwen2.5-coder:32b-base-q6_K
      gpu:
        enabled: true
        type: nvidia
        nvidiaResource: "nvidia.com/gpu"
        number: 1
    persistentVolume:
      enabled: true
      size: 256Gi
      storageClass: longhorn
      # autogenerated by cluster on initial sync
      existingClaim: open-webui-ollama
      #volumeName: pvc-58d2f98b-7b6c-40bc-b30a-d0e52595d2ca
