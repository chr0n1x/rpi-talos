# persistence:
  # changes depending on what you're doing with CSI
  # in my case I have a default longhorn CSI config so this is dynamically
  # created for me
  # volumeName: pvc-7bedf8a1-5966-4448-9902-e42dc7011cd7 

persistence:
  class: smb

docker-registry-ui:
  registry:
    enabled: true
    dataVolume:
      persistentVolumeClaim:
        claimName: longhorn-docker-registry-pvc
    ingress:
      enabled: true
      host: docker.home.k8s
      annotations:
        nginx.ingress.kubernetes.io/proxy-body-size: "0"
        nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
        nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
  ui:
    ingress:
        enabled: true
        # automatically has a prefix of /v2
        host: docker.home.k8s
        annotations:
          nginx.ingress.kubernetes.io/backend-protocol: "HTTP"
          nginx.ingress.kubernetes.io/force-ssl-redirect: "false"
          nginx.ingress.kubernetes.io/ssl-passthrough: "false"
          nginx.ingress.kubernetes.io/auth-url: https://oauth2-proxy.home.k8s:30443/oauth2/auth
          # don't feel too good about this; ideally should be $server_port, but
          # using a NodePort instead of an actual LB doesn't seem to allow this (TBD)
          nginx.ingress.kubernetes.io/auth-signin: "https://oauth2-proxy.home.k8s:30443/oauth2/start?rd=$scheme://$host:30443$request_uri"
          nginx.ingress.kubernetes.io/auth-response-headers: X-Auth-Request-User,X-Auth-Request-Email,X-Forwarded-Groups
